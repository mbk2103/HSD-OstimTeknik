{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n-MCZ0d3u0aO","executionInfo":{"status":"ok","timestamp":1747659817251,"user_tz":-180,"elapsed":2476,"user":{"displayName":"Mehmet Burak KARABULUT","userId":"16868455667042140456"}},"outputId":"c00e1d10-4c3e-456c-b3ec-3c81b7d0868f"},"id":"n-MCZ0d3u0aO","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":2,"id":"806c6704","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"806c6704","executionInfo":{"status":"ok","timestamp":1747659823879,"user_tz":-180,"elapsed":6623,"user":{"displayName":"Mehmet Burak KARABULUT","userId":"16868455667042140456"}},"outputId":"1ed3d3d6-d59c-4ca0-f278-a9af9d4a651d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":2}],"source":["import torch\n","torch.cuda.is_available()"]},{"cell_type":"code","execution_count":3,"id":"0e67af9b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0e67af9b","executionInfo":{"status":"ok","timestamp":1747659828494,"user_tz":-180,"elapsed":4609,"user":{"displayName":"Mehmet Burak KARABULUT","userId":"16868455667042140456"}},"outputId":"035eb044-2681-4f3a-a052-35698f712e90"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n","Setup complete ✅ (2 CPUs, 12.7 GB RAM, 41.4/107.7 GB disk)\n"]}],"source":["!pip install ultralytics\n","from IPython import display\n","display.clear_output()\n","\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":4,"id":"c1f5d20f","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"c1f5d20f","executionInfo":{"status":"ok","timestamp":1747664124384,"user_tz":-180,"elapsed":4295884,"user":{"displayName":"Mehmet Burak KARABULUT","userId":"16868455667042140456"}},"outputId":"374add46-cc78-406a-9828-d57999943aba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/HSDTopluluk/Proje-4/Car-Pickup-Truck/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/HSDTopluluk/Proje-4/yolo11n-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=car-truck-segment-yolov11sn-b322, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/segment/car-truck-segment-yolov11sn-b322, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=1, workspace=None\n","Overriding model.yaml nc=80 with nc=3\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n"," 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n"," 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n"," 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n"," 23        [16, 19, 22]  1    684025  ultralytics.nn.modules.head.Segment          [3, 32, 64, [64, 128, 256]]   \n","YOLO11n-seg summary: 203 layers, 2,843,193 parameters, 2,843,177 gradients, 10.4 GFLOPs\n","\n","Transferred 510/561 items from pretrained weights\n","Freezing layer 'model.23.dfl.conv.weight'\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.7±0.3 ms, read: 0.8±0.2 MB/s, size: 3.5 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/HSDTopluluk/Proje-4/Car-Pickup-Truck/train/labels.cache... 180 images, 0 backgrounds, 0 corrupt: 100%|██████████| 180/180 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.5±0.2 ms, read: 1.3±0.6 MB/s, size: 3.9 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/HSDTopluluk/Proje-4/Car-Pickup-Truck/valid/labels.cache... 8 images, 0 backgrounds, 0 corrupt: 100%|██████████| 8/8 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/segment/car-truck-segment-yolov11sn-b322/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0005), 100 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1mruns/segment/car-truck-segment-yolov11sn-b322\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/20         0G     0.5939      2.724      2.878       1.19         11        640: 100%|██████████| 45/45 [03:31<00:00,  4.71s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.47s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8    0.00604          1      0.571      0.476    0.00604          1      0.571      0.401\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/20         0G     0.6514      1.658        2.5      1.217         14        640: 100%|██████████| 45/45 [03:31<00:00,  4.71s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.46s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.776      0.333      0.415      0.355      0.776      0.333      0.415      0.328\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/20         0G     0.7092      1.588      2.178      1.244         13        640: 100%|██████████| 45/45 [03:40<00:00,  4.90s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.93s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8       0.24        0.6      0.324      0.156       0.24        0.6      0.325      0.131\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/20         0G     0.7771      1.552      2.088      1.282          9        640: 100%|██████████| 45/45 [03:26<00:00,  4.59s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<00:00,  5.29s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.621      0.656      0.356      0.261      0.621      0.656      0.373      0.256\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/20         0G     0.6875      1.499      1.867      1.223         13        640: 100%|██████████| 45/45 [03:26<00:00,  4.60s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.26s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.405      0.638      0.474      0.332      0.405      0.638      0.494      0.265\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/20         0G     0.6628      1.393      1.738      1.179         14        640: 100%|██████████| 45/45 [03:27<00:00,  4.62s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.66s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.677      0.667      0.536      0.356      0.677      0.667      0.536      0.345\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       7/20         0G     0.5988      1.219      1.601      1.152          9        640: 100%|██████████| 45/45 [03:28<00:00,  4.64s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.34s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.313      0.666      0.498      0.452      0.451      0.974      0.663       0.47\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       8/20         0G     0.5685      1.219      1.531      1.123         13        640: 100%|██████████| 45/45 [03:32<00:00,  4.73s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.304        0.5      0.365      0.339      0.336      0.833      0.475      0.314\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       9/20         0G     0.5654      1.212      1.552      1.097         13        640: 100%|██████████| 45/45 [03:31<00:00,  4.71s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.90s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.166      0.367      0.251      0.173      0.205        0.7      0.332      0.185\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      10/20         0G     0.5229      1.078      1.438      1.093         13        640: 100%|██████████| 45/45 [03:31<00:00,  4.69s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.76s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.305        0.5      0.406      0.319      0.305        0.5      0.434      0.323\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      11/20         0G     0.5682     0.9899      2.359      1.299          4        640: 100%|██████████| 45/45 [03:26<00:00,  4.60s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.69s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.541      0.348      0.505      0.417      0.646      0.579      0.666      0.428\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      12/20         0G     0.4352     0.8014       2.01      1.135          4        640: 100%|██████████| 45/45 [03:33<00:00,  4.75s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.63s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.475       0.43      0.461      0.399      0.475       0.43      0.461      0.368\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      13/20         0G     0.4031      0.853       1.83      1.142          4        640: 100%|██████████| 45/45 [03:27<00:00,  4.60s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.368      0.934       0.62      0.492      0.368      0.934       0.62      0.477\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      14/20         0G     0.3775     0.7287      1.748        1.1          4        640: 100%|██████████| 45/45 [03:25<00:00,  4.56s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.35s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.331          1      0.525      0.469       0.45      0.948      0.608      0.458\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      15/20         0G     0.3601     0.7242      1.676      1.063          4        640: 100%|██████████| 45/45 [03:26<00:00,  4.58s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.42s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.292      0.667       0.46      0.418      0.465          1      0.611      0.414\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      16/20         0G     0.3419     0.7389      1.643      1.045          4        640: 100%|██████████| 45/45 [03:25<00:00,  4.56s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.80s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.653      0.467      0.332       0.29      0.653      0.467      0.357      0.275\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      17/20         0G     0.3223      0.598      1.551      1.015          4        640: 100%|██████████| 45/45 [03:26<00:00,  4.58s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<00:00,  5.25s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.299      0.667      0.387      0.362      0.303          1       0.43      0.339\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      18/20         0G     0.2782     0.6021      1.383     0.9953          4        640: 100%|██████████| 45/45 [03:25<00:00,  4.56s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.294      0.667      0.455      0.431      0.345          1      0.525      0.422\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      19/20         0G     0.2792      0.599      1.426      1.003          4        640: 100%|██████████| 45/45 [03:26<00:00,  4.59s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.99s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.289      0.667      0.424       0.42      0.355      0.929      0.497      0.388\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      20/20         0G     0.2684     0.5507      1.329     0.9625          4        640: 100%|██████████| 45/45 [03:25<00:00,  4.58s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.91s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.305      0.667      0.469      0.467      0.374          1      0.575      0.426\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","20 epochs completed in 1.187 hours.\n","Optimizer stripped from runs/segment/car-truck-segment-yolov11sn-b322/weights/last.pt, 6.0MB\n","Optimizer stripped from runs/segment/car-truck-segment-yolov11sn-b322/weights/best.pt, 6.0MB\n","\n","Validating runs/segment/car-truck-segment-yolov11sn-b322/weights/best.pt...\n","Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n","YOLO11n-seg summary (fused): 113 layers, 2,835,153 parameters, 0 gradients, 10.2 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\r                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n","WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n","WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n","WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n","WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n","WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n","WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n","WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all          8          8      0.367      0.932       0.62      0.492      0.367      0.932       0.62      0.477\n","                   car          2          2      0.206          1      0.497       0.37      0.206          1      0.497      0.345\n","                pickup          5          5      0.496          1      0.866      0.806      0.496          1      0.866      0.786\n","                 truck          1          1      0.398      0.796      0.497      0.298      0.398      0.796      0.497      0.298\n","Speed: 2.5ms preprocess, 313.2ms inference, 0.0ms loss, 4.0ms postprocess per image\n","Results saved to \u001b[1mruns/segment/car-truck-segment-yolov11sn-b322\u001b[0m\n"]}],"source":["from ultralytics import YOLO\n","\n","# Load a model\n","#model = YOLO('yolov8n-seg.yaml')  # build a new model from YAML\n","#model = YOLO('/content/drive/MyDrive/HSD Topluluk/Proje-4/yolo11n.pt')  # load a pretrained model (recommended for training)\n","model = YOLO('/content/drive/MyDrive/HSDTopluluk/Proje-4/yolo11n-seg.pt')  # load a pretrained model (recommended for training)\n","#model = YOLO('yolov8n-seg.yaml').load('yolov8n.pt')  # build from YAML and transfer weights\n","\n","# Train the model\n","results = model.train(data='/content/drive/MyDrive/HSDTopluluk/Proje-4/Car-Pickup-Truck/data.yaml', epochs=20, imgsz=640, device='cpu', workers=1, batch=4, name='car-truck-segment-yolov11sn-b32')\n"]},{"cell_type":"code","execution_count":13,"id":"709a9489","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"709a9489","executionInfo":{"status":"ok","timestamp":1747664300771,"user_tz":-180,"elapsed":7935,"user":{"displayName":"Mehmet Burak KARABULUT","userId":"16868455667042140456"}},"outputId":"366cbdba-31cb-446c-b34e-d3c2451b2919"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n","YOLO11n-seg summary (fused): 113 layers, 2,835,153 parameters, 0 gradients, 10.2 GFLOPs\n","\n","image 1/1 /content/drive/MyDrive/HSDTopluluk/Proje-4/Car-Pickup-Truck/test/images/t21_jpg.rf.78b4d5a38891c12f23f45f941486f221.jpg: 480x640 1 car, 1 pickup, 304.5ms\n","Speed: 9.0ms preprocess, 304.5ms inference, 16.5ms postprocess per image at shape (1, 3, 480, 640)\n","Results saved to \u001b[1mruns/segment/predict7\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/predict\n"]}],"source":["!yolo task=segment mode=predict model=/content/runs/segment/car-truck-segment-yolov11sn-b322/weights/best.pt source='/content/drive/MyDrive/HSDTopluluk/Proje-4/Car-Pickup-Truck/test/images/t21_jpg.rf.78b4d5a38891c12f23f45f941486f221.jpg' show_boxes=True save=True"]},{"cell_type":"code","execution_count":7,"id":"0326f189","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"colab":{"base_uri":"https://localhost:8080/"},"id":"0326f189","executionInfo":{"status":"ok","timestamp":1747664193965,"user_tz":-180,"elapsed":10147,"user":{"displayName":"Mehmet Burak KARABULUT","userId":"16868455667042140456"}},"outputId":"20454e06-9d65-4716-c323-bb734b7b0d71"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ 'data' argument is missing. Using default 'data=coco8-seg.yaml'.\n","Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n","YOLO11n-seg summary (fused): 113 layers, 2,835,153 parameters, 0 gradients, 10.2 GFLOPs\n","\n","WARNING ⚠️ Dataset 'coco8-seg.yaml' images not found, missing path '/content/datasets/coco8-seg/images/val'\n","Downloading https://ultralytics.com/assets/coco8-seg.zip to '/content/datasets/coco8-seg.zip'...\n","100% 439k/439k [00:00<00:00, 27.9MB/s]\n","Unzipping /content/datasets/coco8-seg.zip to /content/datasets/coco8-seg...: 100% 25/25 [00:00<00:00, 1494.68file/s]\n","Dataset download success ✅ (1.0s), saved to \u001b[1m/content/datasets\u001b[0m\n","\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1020.3±688.0 MB/s, size: 54.0 KB)\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8-seg/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100% 4/4 [00:00<00:00, 380.57it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco8-seg/labels/val.cache\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0% 0/1 [00:01<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/yolo\", line 8, in <module>\n","    sys.exit(entrypoint())\n","             ^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/cfg/__init__.py\", line 981, in entrypoint\n","    getattr(model, mode)(**overrides)  # default args from model\n","    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\", line 630, in val\n","    validator(model=self.model)\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/validator.py\", line 225, in __call__\n","    self.update_metrics(preds, batch)\n","  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/models/yolo/segment/val.py\", line 186, in update_metrics\n","    self.confusion_matrix.process_batch(predn, bbox, cls)\n","  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/utils/metrics.py\", line 386, in process_batch\n","    self.matrix[self.nc, gc] += 1  # true background\n","    ~~~~~~~~~~~^^^^^^^^^^^^^\n","IndexError: index 16 is out of bounds for axis 1 with size 4\n"]}],"source":["!yolo task=segment mode=val model=/content/runs/segment/car-truck-segment-yolov11sn-b322/weights/best.pt"]},{"cell_type":"code","execution_count":null,"id":"f81206f4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f81206f4","executionInfo":{"status":"ok","timestamp":1747645179666,"user_tz":-180,"elapsed":40,"user":{"displayName":"Mehmet Burak KARABULUT","userId":"16868455667042140456"}},"outputId":"6884a5dd-5e79-4d35-9203-d67da8573cf2"},"outputs":[{"output_type":"stream","name":"stdout","text":["<function SegmentMetrics.mean_results at 0x7c1af01f39c0>\n","<function ConfusionMatrix.tp_fp at 0x7c1af01f1e40>\n","<function SegmentMetrics.process at 0x7c1af01f3880>\n"]}],"source":["from ultralytics.utils.metrics import ConfusionMatrix\n","from ultralytics.utils.metrics import SegmentMetrics\n","from ultralytics import YOLO\n","\n","model = YOLO('/content/runs/segment/car-truck-segment-yolov11sn-b32/weights/best.pt')  # load a custom model\n","\n","meann=SegmentMetrics.mean_results\n","\n","tp_fp=ConfusionMatrix.tp_fp\n","process=SegmentMetrics.process\n","\n","print(meann)\n","print(tp_fp)\n","print(process)"]},{"cell_type":"code","execution_count":null,"id":"6663a102","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6663a102","executionInfo":{"status":"ok","timestamp":1747645285708,"user_tz":-180,"elapsed":4553,"user":{"displayName":"Mehmet Burak KARABULUT","userId":"16868455667042140456"}},"outputId":"863cd28c-602a-4cb6-9ed8-4190ba203f9d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n","YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.8±0.4 ms, read: 4.6±3.0 MB/s, size: 12.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/HSD Topluluk/Proje-4/Plate-recognition-dataset/valid/labels.cache... 6 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6/6 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all          6          6    0.00333          1      0.698      0.374\n","Speed: 2.0ms preprocess, 214.0ms inference, 0.0ms loss, 7.3ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val3\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["array([    0.37392])"]},"metadata":{},"execution_count":15}],"source":["from ultralytics import YOLO\n","\n","# Load a model\n","#model = YOLO('yolov8n-seg.pt')  # load an official model\n","model = YOLO('/content/runs/detect/plate-detection-yolov11n-batchf/weights/best.pt')  # load a custom model\n","\n","# Validate the model\n","metrics = model.val()  # no arguments needed, dataset and settings remembered\n","metrics.box.map    # map50-95(B)\n","metrics.box.map50  # map50(B)\n","metrics.box.map75  # map75(B)\n","metrics.box.maps   # a list contains map50-95(B) of each category\n","#\n"]},{"cell_type":"code","execution_count":null,"id":"cb1bb7d7","metadata":{"id":"cb1bb7d7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"13a9bb98","metadata":{"id":"13a9bb98"},"outputs":[],"source":["#!yolo task=segment mode=predict model=runs/segment/train3/weights/best.pt source= 'val\\13.jpg'"]},{"cell_type":"code","execution_count":null,"id":"33a06d9b","metadata":{"id":"33a06d9b"},"outputs":[],"source":["from ultralytics import YOLO\n","\n","# Load a model\n","#model = YOLO('yolov8n.pt')  # load an official model\n","model = YOLO('runs/segment/dot-seg-yolov8n-batchf/weights/best.pt')  # load a custom trained\n","\n","# Export the model\n","model.export(format='onnx')\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}